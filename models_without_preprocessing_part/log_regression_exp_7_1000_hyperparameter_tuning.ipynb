{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418d51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "from scipy.special import softmax \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models import model__prior_mu_studentT as model \n",
    "from collections import Counter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "164997a7",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486bee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = pd.read_pickle('../pickle/df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae02517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df.sample(1400,random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a92b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_sampled.iloc[:,:-1].copy()\n",
    "df_target = df_sampled.iloc[:,-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71db3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = scaler.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0fc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features, df_test_features,df_train_target, df_test_target =  train_test_split(df_features,df_target,stratify=df_target,random_state=47, test_size=1/7)\n",
    "\n",
    "df_train_features, df_val_features,df_train_target, df_val_target =  train_test_split(df_train_features,df_train_target,stratify=df_train_target,random_state=47, test_size=1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e2a8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_target = df_train_target.to_numpy()\n",
    "df_test_target = df_test_target.to_numpy()\n",
    "df_val_target = df_val_target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf8c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = df_train_features.shape[1]\n",
    "N_train = df_train_features.shape[0]\n",
    "N_test = df_test_features.shape[0]\n",
    "N_val = df_val_features.shape[0]\n",
    "n_cat = 11 \n",
    "degF=4\n",
    "tau=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1dfc9e9",
   "metadata": {},
   "source": [
    "### Ancestral Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b77aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29f4324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [ 0.40304529  0.59561818 -0.23585745 -0.24577339  0.91754147 -0.04280335\n",
      " -0.22780267 -0.52247453  0.71254979 -1.00743579 -0.12312639 -0.28973902\n",
      "  0.02018443 -0.93218132]\n"
     ]
    }
   ],
   "source": [
    "# sample coefficients (beta)\n",
    "beta = np.random.normal(0,1,size=D)\n",
    "print(\"beta:\", beta)\n",
    "\n",
    "beta_array = np.zeros((n_cat,D))\n",
    "\n",
    "for i in range(n_cat):\n",
    "    \n",
    "    beta_array[i,:] = np.random.normal(0,1,size=D)\n",
    "    \n",
    "# sample observations (y's)\n",
    "y = np.zeros((N_train,n_cat))\n",
    "for n in range(N_train):\n",
    "    \n",
    "    probs = np.zeros(n_cat)\n",
    "    for i in range(n_cat):\n",
    "        probs[i] = np.array([(np.dot(beta_array[i,:], df_train_features[n,:]))])\n",
    "        \n",
    "    p =  softmax(probs)\n",
    "    y[n,:] = np.random.multinomial(1, p)  #binomial with one trial is equivalent to bernoulli\n",
    "    #y[n] = int(p > 0.5) # alternative version without observation noise\n",
    "    #print(\" p=, y[n]=\"  (n, p, y[n,:]))\n",
    "    #print('n, p and y ', n, p, y[n,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ce21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.array([]) \n",
    "for i in y:\n",
    "    label_array = np.append(label_array,np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d126f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c36a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.088\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", 1.0*np.sum(label_array == df_train_target.flatten()) / len(df_train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19960313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(df_train_features).float()\n",
    "y_train = torch.tensor(df_train_target.flatten()).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08672c0a",
   "metadata": {},
   "source": [
    "#### Final Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b5f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "degF=4\n",
    "tau=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd828b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 4055.2\n",
      "[1000] ELBO: 3613.6\n",
      "[2000] ELBO: 3057.9\n",
      "[3000] ELBO: 2740.5\n",
      "[4000] ELBO: 2516.3\n",
      "[5000] ELBO: 2354.8\n",
      "[6000] ELBO: 2205.5\n",
      "[7000] ELBO: 2043.2\n",
      "[8000] ELBO: 2009.9\n",
      "[9000] ELBO: 1948.5\n",
      "[10000] ELBO: 1902.0\n",
      "[11000] ELBO: 1835.1\n",
      "[12000] ELBO: 1801.0\n",
      "[13000] ELBO: 1780.0\n",
      "[14000] ELBO: 1778.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MNIS\\AppData\\Local\\Temp\\ipykernel_20652\\1890058607.py:41: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n",
      "  mean_alpha = mean_alpha.T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0001: 0.475}\n",
      "[0] ELBO: 1751.2\n",
      "[1000] ELBO: 1685.5\n",
      "[2000] ELBO: 1655.3\n",
      "[3000] ELBO: 1656.5\n",
      "[4000] ELBO: 1639.5\n",
      "[5000] ELBO: 1638.5\n",
      "[6000] ELBO: 1636.6\n",
      "[7000] ELBO: 1631.2\n",
      "[8000] ELBO: 1628.0\n",
      "[9000] ELBO: 1619.9\n",
      "[10000] ELBO: 1627.8\n",
      "[11000] ELBO: 1623.5\n",
      "[12000] ELBO: 1634.9\n",
      "[13000] ELBO: 1635.3\n",
      "[14000] ELBO: 1621.5\n",
      "{0.001: 0.475}\n",
      "[0] ELBO: 1628.5\n",
      "[1000] ELBO: 1711.9\n",
      "[2000] ELBO: 1659.0\n",
      "[3000] ELBO: 1701.7\n",
      "[4000] ELBO: 1746.1\n",
      "[5000] ELBO: 1716.7\n",
      "[6000] ELBO: 1742.4\n",
      "[7000] ELBO: 1695.1\n",
      "[8000] ELBO: 1712.8\n",
      "[9000] ELBO: 1680.6\n",
      "[10000] ELBO: 1702.2\n",
      "[11000] ELBO: 1702.8\n",
      "[12000] ELBO: 1719.5\n",
      "[13000] ELBO: 1685.1\n",
      "[14000] ELBO: 1695.6\n",
      "{0.01: 0.475}\n"
     ]
    }
   ],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 15000\n",
    "\n",
    "learning_rates = [0.0001,0.001,0.01]\n",
    "# Setup the optimizer\n",
    "acc_val_lr = []\n",
    "for lr in learning_rates:\n",
    "\n",
    "    adam_params = {\"lr\": lr}\n",
    "    optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "    # Setup the inference algorithm\n",
    "    elbo = Trace_ELBO(num_particles=1)\n",
    "    svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "    # Do gradient steps\n",
    "    for step in range(n_steps):\n",
    "        elbo = svi.step(X_train, n_cat, degF, tau, y_train)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"[%d] ELBO: %.1f\" % (step, elbo))\n",
    "\n",
    "            #ef model(X, n_cat, degF, tau, obs=None):\n",
    "    predictive = Predictive(model, guide=guide, num_samples=2000,\n",
    "                    return_sites=(\"alpha\", \"beta\"))\n",
    "    samples = predictive(X_train, n_cat, degF, tau, y_train)\n",
    "    \n",
    "    \n",
    "    samples_alpha = samples[\"alpha\"].detach().squeeze()\n",
    "    samples_beta = samples[\"beta\"].detach().squeeze()\n",
    "    \n",
    "    \n",
    "    mean_betas = samples_beta.mean(axis=0)\n",
    "    mean_betas = mean_betas.T\n",
    "    mean_alpha = samples_alpha.mean(axis=0)\n",
    "    mean_alpha = mean_alpha.T\n",
    "    \n",
    "    \n",
    "    y_val_pred = np.zeros((N_val,n_cat))\n",
    "    \n",
    "    for n in range(N_val):\n",
    "\n",
    "        probs = np.zeros(n_cat)\n",
    "        for i in range(n_cat):\n",
    "            probs[i] = np.array([mean_alpha[i]+(np.dot(mean_betas[i,:], df_val_features[n,:]))])\n",
    "\n",
    "        p =  softmax(probs)\n",
    "        y_val_pred[n,:] = np.argmax(p)  #binomial with one trial is equivalent to bernoulli\n",
    "        \n",
    "    y_val_pred = y_val_pred[:,0]\n",
    "            \n",
    "    acc = 1.0*np.sum(y_val_pred == df_val_target.flatten()) / len(df_val_target)\n",
    "    print({lr:acc})\n",
    "    acc_val_lr.append({lr:acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b9e834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for learning rate 0.0001 is 0.475\n",
      "The accuracy value for learning rate 0.001 is 0.475\n",
      "The accuracy value for learning rate 0.01 is 0.475\n"
     ]
    }
   ],
   "source": [
    "for p in acc_val_lr:\n",
    "\n",
    "    lr = list(p.keys())[0]\n",
    "    acc = list(p.values())[0]\n",
    "\n",
    "    print(f'The accuracy value for learning rate {lr} is {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
