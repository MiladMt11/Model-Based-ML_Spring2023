{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418d51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MNIS\\Anaconda3\\envs\\ModelBasedML38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "from scipy.special import softmax \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "164997a7",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486bee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bb6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your own local path please!\n",
    "path = \"./Data/\"\n",
    "file_name = [\"train.csv\", \"test.csv\", \"submission.csv\"]\n",
    "df_train = pd.read_csv(path + file_name[0])\n",
    "df_test = pd.read_csv(path + file_name[1])\n",
    "df_submission = pd.read_csv(path + file_name[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67eee01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['key'] = df_train['key'].fillna(df_train['key'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6df99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['instrumentalness'] = df_train['instrumentalness'].fillna(df_train['instrumentalness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d897c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Popularity'] = df_train['Popularity'].fillna(df_train['Popularity'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b77aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9915e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_train[['Popularity', 'danceability', 'energy',\n",
    "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "       'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "       'duration_in min/ms', 'time_signature']].copy()\n",
    "df_features[df_features.columns] = scaler.fit_transform(df_features)\n",
    "\n",
    "df_train_target = df_train[['Class']].sample(1000)\n",
    "df_train_target_index = df_train_target.index\n",
    "df_train_features = df_features.iloc[df_train_target_index].to_numpy()\n",
    "df_train_target = df_train_target.to_numpy()\n",
    "\n",
    "df_features_new = df_features\n",
    "df_features_new[['Class']] = df_train[['Class']]\n",
    "# df_features_new\n",
    "\n",
    "df_rest_features = df_features_new.drop(index = df_train_target_index).reset_index()\n",
    "# df_rest_target = df_train_target.iloc[~df_train_target_index].reset_index()\n",
    "df_rest_features = df_rest_features.drop(columns = {df_rest_features.columns[0]})\n",
    "df_test_target = df_rest_features[['Class']].sample(200)\n",
    "df_test_target_index = df_test_target.index\n",
    "\n",
    "df_test_features = df_rest_features.iloc[df_test_target_index]\n",
    "df_test_features = df_test_features.drop(columns={'Class'}).to_numpy()\n",
    "\n",
    "df_test_target = df_test_target.to_numpy()\n",
    "\n",
    "\n",
    "# df_rest_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40faf21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 14), (200, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rest_02 = df_rest_features.drop(index = df_test_target_index).reset_index()\n",
    "df_rest_02 = df_rest_02.drop(columns = {df_rest_02.columns[0]})\n",
    "df_val_target = df_rest_02[['Class']].sample(200)\n",
    "df_val_target_index = df_val_target.index\n",
    "\n",
    "df_val_features = df_rest_02.iloc[df_val_target_index]\n",
    "df_val_features = df_val_features.drop(columns={'Class'}).to_numpy()\n",
    "\n",
    "df_val_target = df_val_target.to_numpy()\n",
    "df_val_features.shape, df_val_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bf8c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = df_train_features.shape[1]\n",
    "N_train = df_train_features.shape[0]\n",
    "N_test = df_test_features.shape[0]\n",
    "N_val = df_val_features.shape[0]\n",
    "n_cat = 11 \n",
    "degF=5\n",
    "tau=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1dfc9e9",
   "metadata": {},
   "source": [
    "### Ancestral Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29f4324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [-1.1131725   1.88309417  2.48329262 -1.76659086 -0.00330663 -0.1915277\n",
      "  0.61044673 -0.36818506  0.95252189  0.67795511 -0.6937733  -0.38363578\n",
      " -0.82296093  0.23970234]\n"
     ]
    }
   ],
   "source": [
    "# sample coefficients (beta)\n",
    "beta = np.random.normal(0,1,size=D)\n",
    "print(\"beta:\", beta)\n",
    "\n",
    "beta_array = np.zeros((n_cat,D))\n",
    "\n",
    "for i in range(n_cat):\n",
    "    \n",
    "    beta_array[i,:] = np.random.normal(0,1,size=D)\n",
    "    \n",
    "# sample observations (y's)\n",
    "y = np.zeros((N_train,n_cat))\n",
    "for n in range(N_train):\n",
    "    \n",
    "    probs = np.zeros(n_cat)\n",
    "    for i in range(n_cat):\n",
    "        probs[i] = np.array([(np.dot(beta_array[i,:], df_train_features[n,:]))])\n",
    "        \n",
    "    p =  softmax(probs)\n",
    "    y[n,:] = np.random.multinomial(1, p)  #binomial with one trial is equivalent to bernoulli\n",
    "    #y[n] = int(p > 0.5) # alternative version without observation noise\n",
    "    #print(\" p=, y[n]=\"  (n, p, y[n,:]))\n",
    "    #print('n, p and y ', n, p, y[n,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ce21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.array([]) \n",
    "for i in y:\n",
    "    label_array = np.append(label_array,np.argmax(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d126f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2.0: 87,\n",
       "         7.0: 227,\n",
       "         5.0: 104,\n",
       "         8.0: 123,\n",
       "         6.0: 47,\n",
       "         3.0: 74,\n",
       "         1.0: 103,\n",
       "         10.0: 88,\n",
       "         0.0: 73,\n",
       "         9.0: 47,\n",
       "         4.0: 27})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(label_array)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c36a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.073\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", 1.0*np.sum(label_array == df_train_target.flatten()) / len(df_train_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0ff3efc",
   "metadata": {},
   "source": [
    "### Model implementation with Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6719dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, n_cat, degF, tau, obs=None):\n",
    "    \n",
    "    input_dim = X.shape[1]\n",
    "    \n",
    "    \n",
    "    mu_beta = pyro.sample(\"mu_beta\", dist.StudentT(df=torch.ones(n_cat)*degF, \n",
    "                                                   loc=torch.zeros(n_cat), \n",
    "                                                   scale=torch.ones(n_cat)).to_event()) # Prior for the bias mean      \n",
    "    sigma_beta  = pyro.sample(\"sigma_beta\",  dist.HalfCauchy(tau*torch.ones(n_cat)).to_event()) # Prior for the bias standard deviation\n",
    "    \n",
    "    beta  = pyro.sample(\"beta\", dist.Normal(mu_beta*torch.ones(n_cat), \n",
    "                                            sigma_beta*torch.ones(input_dim, n_cat)).to_event()) # Priors for the regression coefficents\n",
    "\n",
    "    alpha = pyro.sample(\"alpha\", dist.Normal(torch.zeros(1, n_cat), \n",
    "                                             5.*torch.ones(1, n_cat)).to_event())  # Prior for the bias/intercept\n",
    "    \n",
    "    \n",
    "    with pyro.plate(\"data\"):\n",
    "        y = pyro.sample(\"y\", dist.Categorical(logits=alpha + X.matmul(beta)), obs=obs)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19960313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(df_train_features).float()\n",
    "y_train = torch.tensor(df_train_target.flatten()).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08672c0a",
   "metadata": {},
   "source": [
    "#### Final Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b5f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "degF=5\n",
    "tau=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abd828b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 4433.5\n",
      "[1000] ELBO: 3841.0\n",
      "[2000] ELBO: 3244.7\n",
      "[3000] ELBO: 2886.3\n",
      "[4000] ELBO: 2615.0\n",
      "[5000] ELBO: 2443.0\n",
      "[6000] ELBO: 2225.8\n",
      "[7000] ELBO: 2168.9\n",
      "[8000] ELBO: 2111.7\n",
      "[9000] ELBO: 1988.7\n",
      "{0.0001: 0.445}\n",
      "[0] ELBO: 1931.3\n",
      "[1000] ELBO: 1730.5\n",
      "[2000] ELBO: 1682.8\n",
      "[3000] ELBO: 1661.3\n",
      "[4000] ELBO: 1656.7\n",
      "[5000] ELBO: 1644.1\n",
      "[6000] ELBO: 1638.6\n",
      "[7000] ELBO: 1640.4\n",
      "[8000] ELBO: 1634.9\n",
      "[9000] ELBO: 1634.4\n",
      "{0.001: 0.475}\n",
      "[0] ELBO: 1631.6\n",
      "[1000] ELBO: 1690.9\n",
      "[2000] ELBO: 1737.2\n",
      "[3000] ELBO: 1690.1\n",
      "[4000] ELBO: 1715.4\n",
      "[5000] ELBO: 1690.9\n",
      "[6000] ELBO: 1697.8\n",
      "[7000] ELBO: 1694.6\n",
      "[8000] ELBO: 1691.5\n",
      "[9000] ELBO: 1732.4\n",
      "{0.01: 0.47}\n"
     ]
    }
   ],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 10000\n",
    "\n",
    "learning_rates = [0.0001,0.001,0.01]\n",
    "# Setup the optimizer\n",
    "acc_val_lr = []\n",
    "for lr in learning_rates:\n",
    "\n",
    "    adam_params = {\"lr\": lr}\n",
    "    optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "    # Setup the inference algorithm\n",
    "    elbo = Trace_ELBO(num_particles=1)\n",
    "    svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "    # Do gradient steps\n",
    "    for step in range(n_steps):\n",
    "        elbo = svi.step(X_train, n_cat, degF, tau, y_train)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"[%d] ELBO: %.1f\" % (step, elbo))\n",
    "\n",
    "            #ef model(X, n_cat, degF, tau, obs=None):\n",
    "    predictive = Predictive(model, guide=guide, num_samples=2000,\n",
    "                    return_sites=(\"alpha\", \"beta\"))\n",
    "    samples = predictive(X_train, n_cat, degF, tau, y_train)\n",
    "    \n",
    "    \n",
    "    samples_alpha = samples[\"alpha\"].detach().squeeze()\n",
    "    samples_beta = samples[\"beta\"].detach().squeeze()\n",
    "    \n",
    "    \n",
    "    mean_betas = samples_beta.mean(axis=0)\n",
    "    mean_betas = mean_betas.T\n",
    "    mean_alpha = samples_alpha.mean(axis=0)\n",
    "    mean_alpha = mean_alpha.T\n",
    "    \n",
    "    \n",
    "    y_val_pred = np.zeros((N_val,n_cat))\n",
    "    \n",
    "    for n in range(N_val):\n",
    "\n",
    "        probs = np.zeros(n_cat)\n",
    "        for i in range(n_cat):\n",
    "            probs[i] = np.array([mean_alpha[i]+(np.dot(mean_betas[i,:], df_val_features[n,:]))])\n",
    "\n",
    "        p =  softmax(probs)\n",
    "        y_val_pred[n,:] = np.argmax(p)  #binomial with one trial is equivalent to bernoulli\n",
    "        \n",
    "    y_val_pred = y_val_pred[:,0]\n",
    "            \n",
    "    acc = 1.0*np.sum(y_val_pred == df_val_target.flatten()) / len(df_val_target)\n",
    "    print({lr:acc})\n",
    "    acc_val_lr.append({lr:acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b9e834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for learning rate 0.0001 is 0.445\n",
      "The accuracy value for learning rate 0.001 is 0.475\n",
      "The accuracy value for learning rate 0.01 is 0.47\n"
     ]
    }
   ],
   "source": [
    "for p in acc_val_lr:\n",
    "\n",
    "    lr = list(p.keys())[0]\n",
    "    acc = list(p.values())[0]\n",
    "\n",
    "    print(f'The accuracy value for learning rate {lr} is {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
