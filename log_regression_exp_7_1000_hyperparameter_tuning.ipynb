{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418d51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "from scipy.special import softmax \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, ClippedAdam\n",
    "from pyro.infer import Predictive\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164997a7",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "486bee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91bb6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your own local path please!\n",
    "path = \"./Data/\"\n",
    "file_name = [\"train.csv\", \"test.csv\", \"submission.csv\"]\n",
    "df_train = pd.read_csv(path + file_name[0])\n",
    "df_test = pd.read_csv(path + file_name[1])\n",
    "df_submission = pd.read_csv(path + file_name[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67eee01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['key'] = df_train['key'].fillna(df_train['key'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6df99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['instrumentalness'] = df_train['instrumentalness'].fillna(df_train['instrumentalness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d897c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Popularity'] = df_train['Popularity'].fillna(df_train['Popularity'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a1186c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.drop(['Artist Name','Track Name'],axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ae02517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df.sample(1400,random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a92b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_sampled.iloc[:,:-1].copy()\n",
    "df_target = df_sampled.iloc[:,-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71db3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = scaler.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f0fc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features, df_test_features,df_train_target, df_test_target =  train_test_split(df_features,df_target,stratify=df_target,random_state=47, test_size=1/7)\n",
    "\n",
    "df_train_features, df_val_features,df_train_target, df_val_target =  train_test_split(df_train_features,df_train_target,stratify=df_train_target,random_state=47, test_size=1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e2a8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_target = df_train_target.to_numpy()\n",
    "df_test_target = df_test_target.to_numpy()\n",
    "df_val_target = df_val_target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bf8c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = df_train_features.shape[1]\n",
    "N_train = df_train_features.shape[0]\n",
    "N_test = df_test_features.shape[0]\n",
    "N_val = df_val_features.shape[0]\n",
    "n_cat = 11 \n",
    "degF=4\n",
    "tau=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dfc9e9",
   "metadata": {},
   "source": [
    "### Ancestral Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b77aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d29f4324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [-0.00367606 -0.02760378  1.60360266 -1.100991   -0.840607    0.12969186\n",
      " -0.72335742  0.41421535  0.21514235 -3.32248393  0.73452844  1.15828269\n",
      " -0.13558812  0.30848633]\n"
     ]
    }
   ],
   "source": [
    "# sample coefficients (beta)\n",
    "beta = np.random.normal(0,1,size=D)\n",
    "print(\"beta:\", beta)\n",
    "\n",
    "beta_array = np.zeros((n_cat,D))\n",
    "\n",
    "for i in range(n_cat):\n",
    "    \n",
    "    beta_array[i,:] = np.random.normal(0,1,size=D)\n",
    "    \n",
    "# sample observations (y's)\n",
    "y = np.zeros((N_train,n_cat))\n",
    "for n in range(N_train):\n",
    "    \n",
    "    probs = np.zeros(n_cat)\n",
    "    for i in range(n_cat):\n",
    "        probs[i] = np.array([(np.dot(beta_array[i,:], df_train_features[n,:]))])\n",
    "        \n",
    "    p =  softmax(probs)\n",
    "    y[n,:] = np.random.multinomial(1, p)  #binomial with one trial is equivalent to bernoulli\n",
    "    #y[n] = int(p > 0.5) # alternative version without observation noise\n",
    "    #print(\" p=, y[n]=\"  (n, p, y[n,:]))\n",
    "    #print('n, p and y ', n, p, y[n,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51ce21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.array([]) \n",
    "for i in y:\n",
    "    label_array = np.append(label_array,np.argmax(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d126f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({10.0: 44,\n",
       "         6.0: 118,\n",
       "         9.0: 109,\n",
       "         8.0: 157,\n",
       "         1.0: 82,\n",
       "         2.0: 129,\n",
       "         3.0: 109,\n",
       "         5.0: 79,\n",
       "         7.0: 112,\n",
       "         4.0: 45,\n",
       "         0.0: 16})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(label_array)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c36a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.109\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", 1.0*np.sum(label_array == df_train_target.flatten()) / len(df_train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff3efc",
   "metadata": {},
   "source": [
    "### Model implementation with Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6719dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, n_cat, degF, tau, obs=None):\n",
    "    \n",
    "    input_dim = X.shape[1]\n",
    "    \n",
    "    \n",
    "    mu_beta = pyro.sample(\"mu_beta\", dist.StudentT(df=torch.ones(n_cat)*degF, \n",
    "                                                   loc=torch.zeros(n_cat), \n",
    "                                                   scale=torch.ones(n_cat)).to_event()) # Prior for the bias mean      \n",
    "    sigma_beta  = pyro.sample(\"sigma_beta\",  dist.HalfCauchy(tau*torch.ones(n_cat)).to_event()) # Prior for the bias standard deviation\n",
    "    \n",
    "    beta  = pyro.sample(\"beta\", dist.Normal(mu_beta*torch.ones(n_cat), \n",
    "                                            sigma_beta*torch.ones(input_dim, n_cat)).to_event()) # Priors for the regression coefficents\n",
    "\n",
    "    alpha = pyro.sample(\"alpha\", dist.Normal(torch.zeros(1, n_cat), \n",
    "                                             5.*torch.ones(1, n_cat)).to_event())  # Prior for the bias/intercept\n",
    "    \n",
    "    \n",
    "    with pyro.plate(\"data\"):\n",
    "        y = pyro.sample(\"y\", dist.Categorical(logits=alpha + X.matmul(beta)), obs=obs)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19960313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(df_train_features).float()\n",
    "y_train = torch.tensor(df_train_target.flatten()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08672c0a",
   "metadata": {},
   "source": [
    "#### Final Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8b5f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "degF=4\n",
    "tau=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abd828b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ELBO: 5604.9\n",
      "[1000] ELBO: 5038.4\n",
      "[2000] ELBO: 4545.6\n",
      "[3000] ELBO: 3970.2\n",
      "[4000] ELBO: 3543.0\n",
      "[5000] ELBO: 3171.4\n",
      "[6000] ELBO: 2884.2\n",
      "[7000] ELBO: 2806.8\n",
      "[8000] ELBO: 2558.8\n",
      "[9000] ELBO: 2453.0\n",
      "[10000] ELBO: 2352.1\n",
      "[11000] ELBO: 2182.8\n",
      "[12000] ELBO: 2112.9\n",
      "[13000] ELBO: 2044.0\n",
      "[14000] ELBO: 1967.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nima\\AppData\\Local\\Temp/ipykernel_16516/1890058607.py:41: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n",
      "  mean_alpha = mean_alpha.T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0001: 0.455}\n",
      "[0] ELBO: 1935.6\n",
      "[1000] ELBO: 1689.2\n",
      "[2000] ELBO: 1665.3\n",
      "[3000] ELBO: 1662.1\n",
      "[4000] ELBO: 1651.4\n",
      "[5000] ELBO: 1646.5\n",
      "[6000] ELBO: 1639.0\n",
      "[7000] ELBO: 1637.3\n",
      "[8000] ELBO: 1643.8\n",
      "[9000] ELBO: 1640.3\n",
      "[10000] ELBO: 1636.1\n",
      "[11000] ELBO: 1627.8\n",
      "[12000] ELBO: 1623.4\n",
      "[13000] ELBO: 1634.8\n",
      "[14000] ELBO: 1627.4\n",
      "{0.001: 0.46}\n",
      "[0] ELBO: 1625.9\n",
      "[1000] ELBO: 1668.3\n",
      "[2000] ELBO: 1690.8\n",
      "[3000] ELBO: 1693.9\n",
      "[4000] ELBO: 1691.2\n",
      "[5000] ELBO: 1679.1\n",
      "[6000] ELBO: 1712.0\n",
      "[7000] ELBO: 1724.5\n",
      "[8000] ELBO: 1698.3\n",
      "[9000] ELBO: 1690.2\n",
      "[10000] ELBO: 1697.3\n",
      "[11000] ELBO: 1682.0\n",
      "[12000] ELBO: 1696.1\n",
      "[13000] ELBO: 1707.1\n",
      "[14000] ELBO: 1740.3\n",
      "{0.01: 0.445}\n"
     ]
    }
   ],
   "source": [
    "# Define guide function\n",
    "guide = AutoMultivariateNormal(model)\n",
    "\n",
    "# Reset parameter values\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Define the number of optimization steps\n",
    "n_steps = 15000\n",
    "\n",
    "learning_rates = [0.0001,0.001,0.01]\n",
    "# Setup the optimizer\n",
    "acc_val_lr = []\n",
    "for lr in learning_rates:\n",
    "\n",
    "    adam_params = {\"lr\": lr}\n",
    "    optimizer = ClippedAdam(adam_params)\n",
    "\n",
    "    # Setup the inference algorithm\n",
    "    elbo = Trace_ELBO(num_particles=1)\n",
    "    svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "    # Do gradient steps\n",
    "    for step in range(n_steps):\n",
    "        elbo = svi.step(X_train, n_cat, degF, tau, y_train)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"[%d] ELBO: %.1f\" % (step, elbo))\n",
    "\n",
    "            #ef model(X, n_cat, degF, tau, obs=None):\n",
    "    predictive = Predictive(model, guide=guide, num_samples=2000,\n",
    "                    return_sites=(\"alpha\", \"beta\"))\n",
    "    samples = predictive(X_train, n_cat, degF, tau, y_train)\n",
    "    \n",
    "    \n",
    "    samples_alpha = samples[\"alpha\"].detach().squeeze()\n",
    "    samples_beta = samples[\"beta\"].detach().squeeze()\n",
    "    \n",
    "    \n",
    "    mean_betas = samples_beta.mean(axis=0)\n",
    "    mean_betas = mean_betas.T\n",
    "    mean_alpha = samples_alpha.mean(axis=0)\n",
    "    mean_alpha = mean_alpha.T\n",
    "    \n",
    "    \n",
    "    y_val_pred = np.zeros((N_val,n_cat))\n",
    "    \n",
    "    for n in range(N_val):\n",
    "\n",
    "        probs = np.zeros(n_cat)\n",
    "        for i in range(n_cat):\n",
    "            probs[i] = np.array([mean_alpha[i]+(np.dot(mean_betas[i,:], df_val_features[n,:]))])\n",
    "\n",
    "        p =  softmax(probs)\n",
    "        y_val_pred[n,:] = np.argmax(p)  #binomial with one trial is equivalent to bernoulli\n",
    "        \n",
    "    y_val_pred = y_val_pred[:,0]\n",
    "            \n",
    "    acc = 1.0*np.sum(y_val_pred == df_val_target.flatten()) / len(df_val_target)\n",
    "    print({lr:acc})\n",
    "    acc_val_lr.append({lr:acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b9e834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for learning rate 0.0001 is 0.455\n",
      "The accuracy value for learning rate 0.001 is 0.46\n",
      "The accuracy value for learning rate 0.01 is 0.445\n"
     ]
    }
   ],
   "source": [
    "for p in acc_val_lr:\n",
    "\n",
    "    lr = list(p.keys())[0]\n",
    "    acc = list(p.values())[0]\n",
    "\n",
    "    print(f'The accuracy value for learning rate {lr} is {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
